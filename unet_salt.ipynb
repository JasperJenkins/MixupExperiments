{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import trange\n",
    "from salt_utils import SaltLoader\n",
    "\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  numpy.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def train(model, epochs=1):\n",
    "  for e in trange(epochs):\n",
    "    for img, mask in model.loader:\n",
    "      model.optim.zero_grad()\n",
    "      prediction = model.net(img.cuda())\n",
    "      ground_truth = mask.cuda()\n",
    "      loss = F.binary_cross_entropy(prediction, ground_truth)\n",
    "      loss.backward()\n",
    "      model.optim.step()\n",
    "      \n",
    "def conv(in_c, out_c):\n",
    "  return nn.Sequential(\n",
    "    nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(out_c),\n",
    "    nn.ELU(inplace=True),\n",
    "    nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(out_c),\n",
    "    nn.ELU(inplace=True),\n",
    "  )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(UNet, self).__init__()\n",
    "    self.down1 = conv(  2,  16) # (  2, 128, 128) --> ( 16, 128, 128)\n",
    "    self.down2 = conv( 16,  32) # ( 16,  64,  64) --> ( 32,  64,  64)\n",
    "    self.down3 = conv( 32,  64) # ( 32,  32,  32) --> ( 64,  32,  32)\n",
    "    self.down4 = conv( 64, 128) # ( 64,  16,  16) --> (128,  16,  16)\n",
    "    self.down5 = conv(128, 256) # (128,   8,   8) --> (256,   8,   8)\n",
    "    self.up1   = conv(384, 128) # (256,  16,  16) --> (128,  16,  16)\n",
    "    self.up2   = conv(192,  64) # (128,  32,  32) --> ( 64,  32,  32)\n",
    "    self.up3   = conv( 96,  32) # ( 64,  64,  64) --> ( 32,  64,  64)\n",
    "    self.up4   = conv( 48,  16) # ( 32, 128, 128) --> ( 16, 128, 128)\n",
    "    self.tail  = nn.Conv2d(16, 1, 1)\n",
    "    self.downpool = nn.MaxPool2d(kernel_size=2)\n",
    "    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x_down_128 = self.down1(x)\n",
    "    x_down_64  = self.down2(self.downpool(x_down_128))\n",
    "    x_down_32  = self.down3(self.downpool(x_down_64))\n",
    "    x_down_16  = self.down4(self.downpool(x_down_32))\n",
    "    x_down_8   = self.down5(self.downpool(x_down_16))\n",
    "    x_up = self.up1(torch.cat([self.upsample(x_down_8), x_down_16], dim=1))\n",
    "    x_up = self.up2(torch.cat([self.upsample(x_up), x_down_32], dim=1))\n",
    "    x_up = self.up3(torch.cat([self.upsample(x_up), x_down_64], dim=1))\n",
    "    x_up = self.up4(torch.cat([self.upsample(x_up), x_down_128],  dim=1))\n",
    "    return self.tail(x_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotted.collection import DottedDict\n",
    "\n",
    "salt_loader = SaltLoader('./train/images/', './train/masks/', './train/depths.csv')\n",
    "\n",
    "model = DottedDict()\n",
    "model['batch_size'] = 16\n",
    "model['net'] = UNet().cuda()\n",
    "model['optim'] = optim.Adam(model.net.parameters(), lr=0.001)\n",
    "model['loader'] = DataLoader(salt_loader, model.batch_size, True, num_workers=2, drop_last=True)\n",
    "model['loader_other'] = DataLoader(salt_loader, model.batch_size, True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "reduce failed to synchronize: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e0c43764b323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-547ced709054>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: reduce failed to synchronize: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "train(model, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
